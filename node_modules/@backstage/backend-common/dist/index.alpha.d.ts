/**
 * Common functionality library for Backstage backends
 *
 * @packageDocumentation
 */

/// <reference types="node" />
/// <reference types="webpack-env" />

import aws from 'aws-sdk';
import { AwsS3Integration } from '@backstage/integration';
import { AzureIntegration } from '@backstage/integration';
import { BackendFeature } from '@backstage/backend-plugin-api';
import { BitbucketCloudIntegration } from '@backstage/integration';
import { BitbucketIntegration } from '@backstage/integration';
import { BitbucketServerIntegration } from '@backstage/integration';
import { CacheService as CacheClient } from '@backstage/backend-plugin-api';
import { CacheServiceOptions as CacheClientOptions } from '@backstage/backend-plugin-api';
import { CacheServiceSetOptions as CacheClientSetOptions } from '@backstage/backend-plugin-api';
import { Config } from '@backstage/config';
import { ConfigService } from '@backstage/backend-plugin-api';
import cors from 'cors';
import Docker from 'dockerode';
import { Duration } from 'luxon';
import { ErrorRequestHandler } from 'express';
import express from 'express';
import { GerritIntegration } from '@backstage/integration';
import { GiteaIntegration } from '@backstage/integration';
import { GithubCredentialsProvider } from '@backstage/integration';
import { GithubIntegration } from '@backstage/integration';
import { GitLabIntegration } from '@backstage/integration';
import { IdentityService } from '@backstage/backend-plugin-api';
import { isChildPath } from '@backstage/cli-common';
import { Knex } from 'knex';
import { KubeConfig } from '@kubernetes/client-node';
import { LifecycleService } from '@backstage/backend-plugin-api';
import { LoadConfigOptionsRemote } from '@backstage/config-loader';
import { Logger } from 'winston';
import { LoggerService } from '@backstage/backend-plugin-api';
import { MergeResult } from 'isomorphic-git';
import { PermissionsService } from '@backstage/backend-plugin-api';
import { DatabaseService as PluginDatabaseManager } from '@backstage/backend-plugin-api';
import { DiscoveryService as PluginEndpointDiscovery } from '@backstage/backend-plugin-api';
import { PluginMetadataService } from '@backstage/backend-plugin-api';
import { PushResult } from 'isomorphic-git';
import { Readable } from 'stream';
import { ReadCommitResult } from 'isomorphic-git';
import { ReadTreeOptions } from '@backstage/backend-plugin-api';
import { ReadTreeResponse } from '@backstage/backend-plugin-api';
import { ReadTreeResponseDirOptions } from '@backstage/backend-plugin-api';
import { ReadTreeResponseFile } from '@backstage/backend-plugin-api';
import { ReadUrlOptions } from '@backstage/backend-plugin-api';
import { ReadUrlResponse } from '@backstage/backend-plugin-api';
import { RequestHandler } from 'express';
import { Router } from 'express';
import { SchedulerService } from '@backstage/backend-plugin-api';
import { SearchOptions } from '@backstage/backend-plugin-api';
import { SearchResponse } from '@backstage/backend-plugin-api';
import { SearchResponseFile } from '@backstage/backend-plugin-api';
import { Server } from 'http';
import { ServiceRef } from '@backstage/backend-plugin-api';
import { TokenManagerService as TokenManager } from '@backstage/backend-plugin-api';
import { TransportStreamOptions } from 'winston-transport';
import { UrlReaderService as UrlReader } from '@backstage/backend-plugin-api';
import { V1PodTemplateSpec } from '@kubernetes/client-node';
import * as winston from 'winston';
import { Writable } from 'stream';

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for AWS S3 buckets.
 *
 * @public
 */
export declare class AwsS3UrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: AwsS3Integration, deps: {
        s3: aws.S3;
        treeResponseFactory: ReadTreeResponseFactory;
    });
    /**
     * If accessKeyId and secretAccessKey are missing, the standard credentials provider chain will be used:
     * https://docs.aws.amazon.com/AWSJavaSDK/latest/javadoc/com/amazonaws/auth/DefaultAWSCredentialsProviderChain.html
     */
    private static buildCredentials;
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(): Promise<SearchResponse>;
    toString(): string;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for Azure repos.
 *
 * @public
 */
export declare class AzureUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: AzureIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files from Bitbucket Cloud.
 *
 * @public
 */
export declare class BitbucketCloudUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: BitbucketCloudIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private getLastCommitShortHash;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files from Bitbucket Server APIs.
 *
 * @public
 */
export declare class BitbucketServerUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: BitbucketServerIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private getLastCommitShortHash;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files from Bitbucket v1 and v2 APIs, such
 * as the one exposed by Bitbucket Cloud itself.
 *
 * @public
 * @deprecated in favor of BitbucketCloudUrlReader and BitbucketServerUrlReader
 */
export declare class BitbucketUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: BitbucketIntegration, logger: LoggerService, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private getLastCommitShortHash;
}

export { CacheClient }

export { CacheClientOptions }

export { CacheClientSetOptions }

/**
 * Implements a Cache Manager which will automatically create new cache clients
 * for plugins when requested. All requested cache clients are created with the
 * connection details provided.
 *
 * @public
 */
export declare class CacheManager {
    /**
     * Keys represent supported `backend.cache.store` values, mapped to factories
     * that return Keyv instances appropriate to the store.
     */
    private readonly storeFactories;
    /**
     * Shared memory store for the in-memory cache client. Sharing the same Map
     * instance ensures get/set/delete operations hit the same store, regardless
     * of where/when a client is instantiated.
     */
    private readonly memoryStore;
    private readonly logger;
    private readonly store;
    private readonly connection;
    private readonly errorHandler;
    /**
     * Creates a new {@link CacheManager} instance by reading from the `backend`
     * config section, specifically the `.cache` key.
     *
     * @param config - The loaded application configuration.
     */
    static fromConfig(config: Config, options?: CacheManagerOptions): CacheManager;
    private constructor();
    /**
     * Generates a PluginCacheManager for consumption by plugins.
     *
     * @param pluginId - The plugin that the cache manager should be created for.
     *        Plugin names should be unique.
     */
    forPlugin(pluginId: string): PluginCacheManager;
    private getClientWithTtl;
    private getRedisClient;
    private getMemcacheClient;
    private getMemoryClient;
    private getNoneClient;
}

/**
 * Options given when constructing a {@link CacheManager}.
 *
 * @public
 */
export declare type CacheManagerOptions = {
    /**
     * An optional logger for use by the PluginCacheManager.
     */
    logger?: LoggerService;
    /**
     * An optional handler for connection errors emitted from the underlying data
     * store.
     */
    onError?: (err: Error) => void;
};

/** @public */
export declare function cacheToPluginCacheManager(cache: CacheClient): PluginCacheManager;

/**
 * Creates a pretty printed winston log formatter.
 *
 * @public
 */
export declare const coloredFormat: winston.Logform.Format;

/**
 * Handles the running of containers, on behalf of others.
 *
 * @public
 */
export declare interface ContainerRunner {
    /**
     * Runs a container image to completion.
     */
    runContainer(opts: RunContainerOptions): Promise<void>;
}

/**
 * A context that is meant to be passed as a ctx variable down the call chain,
 * to pass along scoped information and abort signals.
 *
 * @alpha
 */
export declare interface Context {
    /**
     * Returns an abort signal that triggers when the current context or any of
     * its parents signal for it.
     */
    readonly abortSignal: AbortSignal;
    /**
     * The point in time when the current context shall time out and abort, if
     * applicable.
     */
    readonly deadline: Date | undefined;
    /**
     * Attempts to get a stored value by key from the context.
     *
     * @param key - The key of the value to get
     * @returns The associated value, or undefined if not set
     */
    value<T = unknown>(key: string): T | undefined;
}

/**
 * Common context decorators.
 *
 * @alpha
 */
export declare class Contexts {
    /**
     * Creates a root context.
     *
     * @remarks
     *
     * This should normally only be called near the root of an application. The
     * created context is meant to be passed down into deeper levels, which may or
     * may not make derived contexts out of it.
     */
    static root(): Context;
    /**
     * Creates a derived context, which signals to abort operations either when
     * any parent context signals, or when the given source is aborted.
     *
     * @remarks
     *
     * If the parent context was already aborted, then it is returned as-is.
     *
     * If the given source was already aborted, then a new already-aborted context
     * is returned.
     *
     * @param parentCtx - A parent context that shall be used as a base
     * @param source - An abort controller or signal that you intend to perhaps
     *                 trigger at some later point in time.
     * @returns A new {@link Context}
     */
    static withAbort(parentCtx: Context, source: AbortController | AbortSignal): Context;
    /**
     * Creates a derived context, which signals to abort operations either when
     * any parent context signals, or when the given amount of time has passed.
     * This may affect the deadline.
     *
     * @param parentCtx - A parent context that shall be used as a base
     * @param timeout - The duration of time, after which the derived context will
     *                  signal to abort.
     * @returns A new {@link Context}
     */
    static withTimeoutDuration(parentCtx: Context, timeout: Duration): Context;
    /**
     * Creates a derived context, which signals to abort operations either when
     * any parent context signals, or when the given amount of time has passed.
     * This may affect the deadline.
     *
     * @param parentCtx - A parent context that shall be used as a base
     * @param timeout - The number of milliseconds, after which the derived
     *                  context will signal to abort.
     * @returns A new {@link Context}
     */
    static withTimeoutMillis(parentCtx: Context, timeout: number): Context;
    /**
     * Creates a derived context, which has a specific key-value pair set as well
     * as all key-value pairs that were set in the original context.
     *
     * @param parentCtx - A parent context that shall be used as a base
     * @param key - The key of the value to set
     * @param value - The value, or a function that accepts the previous value (or
     *                undefined if not set yet) and computes the new value
     * @returns A new {@link Context}
     */
    static withValue(parentCtx: Context, key: string, value: unknown | ((previous: unknown | undefined) => unknown)): Context;
}

/**
 * Creates a knex database connection
 *
 * @public
 * @param dbConfig - The database config
 * @param overrides - Additional options to merge with the config
 */
export declare function createDatabaseClient(dbConfig: Config, overrides?: Partial<Knex.Config>, deps?: {
    lifecycle: LifecycleService;
    pluginMetadata: PluginMetadataService;
}): Knex<any, any[]>;

/**
 * Creates a default "root" logger. This also calls {@link setRootLogger} under
 * the hood.
 *
 * @remarks
 *
 * This is the logger instance that will be the foundation for all other logger
 * instances passed to plugins etc, in a given backend.
 *
 * @public
 */
export declare function createRootLogger(options?: winston.LoggerOptions, env?: NodeJS.ProcessEnv): winston.Logger;

/**
 * Creates a new service builder.
 *
 * @public
 */
export declare function createServiceBuilder(_module: NodeModule): ServiceBuilder;

/**
 * Creates a default status checking router, that you can add to your express
 * app.
 *
 * @remarks
 *
 * This adds a `/healthcheck` route (or any other path, if given as an
 * argument), which your infra can call to see if the service is ready to serve
 * requests.
 *
 * @public
 */
export declare function createStatusCheckRouter(options: {
    logger: LoggerService;
    /**
     * The path (including a leading slash) that the health check should be
     * mounted on.
     *
     * @defaultValue '/healthcheck'
     */
    path?: string;
    /**
     * If not implemented, the default express middleware always returns 200.
     * Override this to implement your own logic for a health check.
     */
    statusCheck?: StatusCheck;
}): Promise<express.Router>;

/**
 * Manages database connections for Backstage backend plugins.
 *
 * The database manager allows the user to set connection and client settings on
 * a per pluginId basis by defining a database config block under
 * `plugin.<pluginId>` in addition to top level defaults. Optionally, a user may
 * set `prefix` which is used to prefix generated database names if config is
 * not provided.
 *
 * @public
 */
export declare class DatabaseManager {
    private readonly config;
    private readonly prefix;
    private readonly options?;
    private readonly databaseCache;
    /**
     * Creates a {@link DatabaseManager} from `backend.database` config.
     *
     * @param config - The loaded application configuration.
     * @param options - An optional configuration object.
     */
    static fromConfig(config: Config, options?: DatabaseManagerOptions): DatabaseManager;
    private constructor();
    /**
     * Generates a PluginDatabaseManager for consumption by plugins.
     *
     * @param pluginId - The plugin that the database manager should be created for. Plugin names
     * should be unique as they are used to look up database config overrides under
     * `backend.database.plugin`.
     */
    forPlugin(pluginId: string, deps?: {
        lifecycle: LifecycleService;
        pluginMetadata: PluginMetadataService;
    }): PluginDatabaseManager;
    /**
     * Provides the canonical database name for a given plugin.
     *
     * This method provides the effective database name which is determined using global
     * and plugin specific database config. If no explicit database name is configured
     * and `pluginDivisionMode` is not `schema`, this method will provide a generated name
     * which is the pluginId prefixed with 'backstage_plugin_'. If `pluginDivisionMode` is
     * `schema`, it will fallback to using the default database for the knex instance.
     *
     * @param pluginId - Lookup the database name for given plugin
     * @returns String representing the plugin's database name
     */
    private getDatabaseName;
    /**
     * Provides the client type which should be used for a given plugin.
     *
     * The client type is determined by plugin specific config if present.
     * Otherwise the base client is used as the fallback.
     *
     * @param pluginId - Plugin to get the client type for
     * @returns Object with client type returned as `client` and boolean
     *          representing whether or not the client was overridden as
     *          `overridden`
     */
    private getClientType;
    /**
     * Provides the knexConfig which should be used for a given plugin.
     *
     * @param pluginId - Plugin to get the knexConfig for
     * @returns The merged knexConfig value or undefined if it isn't specified
     */
    private getAdditionalKnexConfig;
    private getEnsureExistsConfig;
    private getPluginDivisionModeConfig;
    /**
     * Provides a Knex connection plugin config by combining base and plugin
     * config.
     *
     * This method provides a baseConfig for a plugin database connector. If the
     * client type has not been overridden, the global connection config will be
     * included with plugin specific config as the base. Values from the plugin
     * connection take precedence over the base. Base database name is omitted for
     * all supported databases excluding SQLite unless `pluginDivisionMode` is set
     * to `schema`.
     */
    private getConnectionConfig;
    /**
     * Provides a Knex database config for a given plugin.
     *
     * This method provides a Knex configuration object along with the plugin's
     * client type.
     *
     * @param pluginId - The plugin that the database config should correspond with
     */
    private getConfigForPlugin;
    /**
     * Provides a partial `Knex.Config` database schema override for a given
     * plugin.
     *
     * @param pluginId - Target plugin to get database schema override
     * @returns Partial `Knex.Config` with database schema override
     */
    private getSchemaOverrides;
    /**
     * Provides a partial `Knex.Config`• database name override for a given plugin.
     *
     * @param pluginId - Target plugin to get database name override
     * @returns Partial `Knex.Config` with database name override
     */
    private getDatabaseOverrides;
    /**
     * Provides a scoped Knex client for a plugin as per application config.
     *
     * @param pluginId - Plugin to get a Knex client for
     * @returns Promise which resolves to a scoped Knex database client for a
     *          plugin
     */
    private getDatabase;
    private startKeepaliveLoop;
}

/**
 * Creation options for {@link DatabaseManager}.
 *
 * @public
 */
export declare type DatabaseManagerOptions = {
    migrations?: PluginDatabaseManager['migrations'];
    logger?: LoggerService;
};

/**
 * A {@link ContainerRunner} for Docker containers.
 *
 * @public
 */
export declare class DockerContainerRunner implements ContainerRunner {
    private readonly dockerClient;
    constructor(options: {
        dockerClient: Docker;
    });
    runContainer(options: RunContainerOptions): Promise<void>;
}

/**
 * Ensures that the given databases all exist, creating them if they do not.
 *
 * @public
 */
export declare function ensureDatabaseExists(dbConfig: Config, ...databases: Array<string>): Promise<void>;

/**
 * Express middleware to handle errors during request processing.
 *
 * This is commonly the very last middleware in the chain.
 *
 * Its primary purpose is not to do translation of business logic exceptions,
 * but rather to be a global catch-all for uncaught "fatal" errors that are
 * expected to result in a 500 error. However, it also does handle some common
 * error types (such as http-error exceptions) and returns the enclosed status
 * code accordingly.
 *
 * @public
 * @returns An Express error request handler
 */
export declare function errorHandler(options?: ErrorHandlerOptions): ErrorRequestHandler;

/**
 * Options passed to the {@link errorHandler} middleware.
 *
 * @public
 */
export declare type ErrorHandlerOptions = {
    /**
     * Whether error response bodies should show error stack traces or not.
     *
     * If not specified, by default shows stack traces only in development mode.
     */
    showStackTraces?: boolean;
    /**
     * Logger instance to log errors.
     *
     * If not specified, the root logger will be used.
     */
    logger?: LoggerService;
    /**
     * Whether any 4xx errors should be logged or not.
     *
     * If not specified, default to only logging 5xx errors.
     */
    logClientErrors?: boolean;
};

/**
 * A {@link @backstage/backend-plugin-api#UrlReaderService} that does a plain fetch of the URL.
 *
 * @public
 */
export declare class FetchUrlReader implements UrlReader {
    /**
     * The factory creates a single reader that will be used for reading any URL that's listed
     * in configuration at `backend.reading.allow`. The allow list contains a list of objects describing
     * targets to allow, containing the following fields:
     *
     * `host`:
     *   Either full hostnames to match, or subdomain wildcard matchers with a leading '*'.
     *   For example 'example.com' and '*.example.com' are valid values, 'prod.*.example.com' is not.
     *
     * `paths`:
     *   An optional list of paths which are allowed. If the list is omitted all paths are allowed.
     */
    static factory: ReaderFactory;
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(): Promise<ReadTreeResponse>;
    search(): Promise<SearchResponse>;
    toString(): string;
}

/**
 * Options that control {@link ReadTreeResponseFactory.fromReadableArray}
 * execution.
 *
 * @public
 */
export declare type FromReadableArrayOptions = Array<{
    /**
     * The raw data itself.
     */
    data: Readable;
    /**
     * The filepath of the data.
     */
    path: string;
}>;

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files in Gerrit.
 *
 * @remarks
 * To be able to link to Git contents for Gerrit providers in a user friendly
 * way we are depending on that there is a Gitiles installation somewhere
 * that we can link to. It is perfectly possible to integrate Gerrit with
 * Backstage without Gitiles since all API calls goes directly to Gerrit.
 *
 * The "host" variable in the config is the Gerrit host. The address where
 * Gitiles is installed may be on the same host but it could be on a
 * separate host. For example a Gerrit instance could be hosted on
 * "gerrit-review.company.com" but the repos could be browsable on a separate
 * host, e.g. "gerrit.company.com" and the human readable URL would then
 * not point to the API host.
 *
 * @public
 */
export declare class GerritUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    private readonly workDir;
    static factory: ReaderFactory;
    constructor(integration: GerritIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    }, workDir: string);
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(): Promise<SearchResponse>;
    toString(): string;
}

/**
 * Gets the current root logger.
 *
 * @public
 */
export declare function getRootLogger(): winston.Logger;

/**
 * A logger that just throws away all messages.
 *
 * @public
 */
export declare function getVoidLogger(): winston.Logger;

/**
 * A convenience wrapper around the `isomorphic-git` library.
 *
 * @public
 */
export declare class Git {
    private readonly config;
    private readonly headers;
    private constructor();
    add(options: {
        dir: string;
        filepath: string;
    }): Promise<void>;
    addRemote(options: {
        dir: string;
        remote: string;
        url: string;
        force?: boolean;
    }): Promise<void>;
    deleteRemote(options: {
        dir: string;
        remote: string;
    }): Promise<void>;
    checkout(options: {
        dir: string;
        ref: string;
    }): Promise<void>;
    branch(options: {
        dir: string;
        ref: string;
    }): Promise<void>;
    commit(options: {
        dir: string;
        message: string;
        author: {
            name: string;
            email: string;
        };
        committer: {
            name: string;
            email: string;
        };
    }): Promise<string>;
    /** https://isomorphic-git.org/docs/en/clone */
    clone(options: {
        url: string;
        dir: string;
        ref?: string;
        depth?: number;
        noCheckout?: boolean;
    }): Promise<void>;
    /** https://isomorphic-git.org/docs/en/currentBranch */
    currentBranch(options: {
        dir: string;
        fullName?: boolean;
    }): Promise<string | undefined>;
    /** https://isomorphic-git.org/docs/en/fetch */
    fetch(options: {
        dir: string;
        remote?: string;
    }): Promise<void>;
    init(options: {
        dir: string;
        defaultBranch?: string;
    }): Promise<void>;
    /** https://isomorphic-git.org/docs/en/merge */
    merge(options: {
        dir: string;
        theirs: string;
        ours?: string;
        author: {
            name: string;
            email: string;
        };
        committer: {
            name: string;
            email: string;
        };
    }): Promise<MergeResult>;
    push(options: {
        dir: string;
        remote: string;
        remoteRef?: string;
        force?: boolean;
    }): Promise<PushResult>;
    /** https://isomorphic-git.org/docs/en/readCommit */
    readCommit(options: {
        dir: string;
        sha: string;
    }): Promise<ReadCommitResult>;
    /** https://isomorphic-git.org/docs/en/resolveRef */
    resolveRef(options: {
        dir: string;
        ref: string;
    }): Promise<string>;
    /** https://isomorphic-git.org/docs/en/log */
    log(options: {
        dir: string;
        ref?: string;
    }): Promise<ReadCommitResult[]>;
    private onAuth;
    private onProgressHandler;
    static fromAuth: (options: {
        username?: string;
        password?: string;
        token?: string;
        logger?: LoggerService;
    }) => Git;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for the Gitea v1 api.
 *
 * @public
 */
export declare class GiteaUrlReader implements UrlReader {
    private readonly integration;
    static factory: ReaderFactory;
    constructor(integration: GiteaIntegration);
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(): Promise<ReadTreeResponse>;
    search(): Promise<SearchResponse>;
    toString(): string;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files through the GitHub v3 APIs, such as
 * the one exposed by GitHub itself.
 *
 * @public
 */
export declare class GithubUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: GithubIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
        credentialsProvider: GithubCredentialsProvider;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private doReadTree;
    private doSearch;
    private getRepoDetails;
    private fetchResponse;
    private fetchJson;
}

/**
 * Implements a {@link @backstage/backend-plugin-api#UrlReaderService} for files on GitLab.
 *
 * @public
 */
export declare class GitlabUrlReader implements UrlReader {
    private readonly integration;
    private readonly deps;
    static factory: ReaderFactory;
    constructor(integration: GitLabIntegration, deps: {
        treeResponseFactory: ReadTreeResponseFactory;
    });
    read(url: string): Promise<Buffer>;
    readUrl(url: string, options?: ReadUrlOptions): Promise<ReadUrlResponse>;
    readTree(url: string, options?: ReadTreeOptions): Promise<ReadTreeResponse>;
    search(url: string, options?: SearchOptions): Promise<SearchResponse>;
    toString(): string;
    private getGitlabFetchUrl;
    private getGitlabArtifactFetchUrl;
    private resolveProjectToId;
}

export { isChildPath }

/**
 * Tries to deduce whether a thrown error is a database conflict.
 *
 * @public
 * @param e - A thrown error
 * @returns True if the error looks like it was a conflict error thrown by a
 *          known database engine
 */
export declare function isDatabaseConflictError(e: unknown): boolean;

/**
 * A {@link ContainerRunner} for Kubernetes.
 *
 * Runs containers leveraging Jobs on a Kubernetes cluster
 *
 * @public
 */
export declare class KubernetesContainerRunner implements ContainerRunner {
    private readonly kubeConfig;
    private readonly batchV1Api;
    private readonly log;
    private readonly name;
    private readonly namespace;
    private readonly mountBase?;
    private readonly podTemplate?;
    private readonly timeoutMs;
    private readonly containerName;
    private getNamespace;
    private validateMountBase;
    constructor(options: KubernetesContainerRunnerOptions);
    runContainer(options: RunContainerOptions): Promise<void>;
    private handleError;
    private watchPod;
    private tailLogs;
    private waitPod;
    private createJob;
    private runJob;
}

/**
 * An existing Kubernetes volume that will be used as base for mounts.
 *
 * Every mount must start with the 'basePath'.
 *
 * @public
 */
export declare type KubernetesContainerRunnerMountBase = {
    volumeName: string;
    basePath: string;
};

/**
 * Options to create a {@link KubernetesContainerRunner}
 *
 * Kubernetes Jobs will be created on the provided 'namespace'
 * and their names will be prefixed with the provided 'name'.
 *
 * 'podTemplate' defines a Pod template for the Jobs. It has to include
 * a volume definition named as the {@link KubernetesContainerRunnerMountBase} 'volumeName'.
 *
 * @public
 */
export declare type KubernetesContainerRunnerOptions = {
    kubeConfig: KubeConfig;
    name: string;
    namespace?: string;
    mountBase?: KubernetesContainerRunnerMountBase;
    podTemplate?: V1PodTemplateSpec;
    timeoutMs?: number;
};

/**
 * @public
 */
export declare type LegacyCreateRouter<TEnv> = (deps: TEnv) => Promise<RequestHandler>;

/**
 * Helper function to create a plugin from a legacy createRouter function and
 * register it with the http router based on the plugin id.
 *
 * @public
 * @remarks
 *
 * This is intended to be used by plugin authors to ease the transition to the
 * new backend system.
 *
 * @example
 *
 *```ts
 *backend.add(legacyPlugin('kafka', import('./plugins/kafka')));
 *```
 */
export declare const legacyPlugin: (name: string, createRouterImport: Promise<{
    default: LegacyCreateRouter<TransformedEnv<{
        cache: CacheClient;
        config: ConfigService;
        database: PluginDatabaseManager;
        discovery: PluginEndpointDiscovery;
        logger: LoggerService;
        permissions: PermissionsService;
        scheduler: SchedulerService;
        tokenManager: TokenManager;
        reader: UrlReader;
        identity: IdentityService;
    }, {
        logger: (log: LoggerService) => Logger;
        cache: (cache: CacheClient) => PluginCacheManager;
    }>>;
}>) => BackendFeature;

/**
 * Load configuration for a Backend.
 *
 * This function should only be called once, during the initialization of the backend.
 *
 * @public
 */
export declare function loadBackendConfig(options: {
    logger: LoggerService;
    remote?: LoadConfigOptionsRemote;
    argv: string[];
}): Promise<Config>;

/** @public */
export declare function loggerToWinstonLogger(logger: LoggerService, opts?: TransportStreamOptions): Logger;

/**
 * Creates a new custom plugin compatibility wrapper.
 *
 * @public
 * @remarks
 *
 * Usually you can use {@link legacyPlugin} directly instead, but you might
 * need to use this if you have customized the plugin environment in your backend.
 */
export declare function makeLegacyPlugin<TEnv extends Record<string, unknown>, TEnvTransforms extends {
    [key in keyof TEnv]?: (dep: TEnv[key]) => unknown;
}>(envMapping: {
    [key in keyof TEnv]: ServiceRef<TEnv[key]>;
}, envTransforms: TEnvTransforms): (name: string, createRouterImport: Promise<{
    default: LegacyCreateRouter<TransformedEnv<TEnv, TEnvTransforms>>;
}>) => BackendFeature;

/**
 * Express middleware to handle requests for missing routes.
 *
 * Should be used as the very last handler in the chain, as it unconditionally
 * returns a 404 status.
 *
 * @public
 * @returns An Express request handler
 */
export declare function notFoundHandler(): RequestHandler;

/**
 * @public
 */
export declare interface PluginCacheManager {
    getClient(options?: CacheClientOptions): CacheClient;
}

export { PluginDatabaseManager }

export { PluginEndpointDiscovery }

/**
 * A factory function that can read config to construct zero or more
 * {@link @backstage/backend-plugin-api#UrlReaderService}s along with a predicate for when it should be used.
 *
 * @public
 */
export declare type ReaderFactory = (options: {
    config: Config;
    logger: LoggerService;
    treeResponseFactory: ReadTreeResponseFactory;
}) => UrlReaderPredicateTuple[];

export { ReadTreeOptions }

export { ReadTreeResponse }

export { ReadTreeResponseDirOptions }

/**
 * A factory for response factories that handle the unpacking and inspection of
 * complex responses such as archive data.
 *
 * @public
 */
export declare interface ReadTreeResponseFactory {
    fromTarArchive(options: ReadTreeResponseFactoryOptions): Promise<ReadTreeResponse>;
    fromZipArchive(options: ReadTreeResponseFactoryOptions): Promise<ReadTreeResponse>;
    fromReadableArray(options: FromReadableArrayOptions): Promise<ReadTreeResponse>;
}

/**
 * Options that control execution of {@link ReadTreeResponseFactory} methods.
 *
 * @public
 */
export declare type ReadTreeResponseFactoryOptions = {
    stream: Readable;
    subpath?: string;
    etag: string;
    filter?: (path: string, info?: {
        size: number;
    }) => boolean;
};

export { ReadTreeResponseFile }

export { ReadUrlOptions }

export { ReadUrlResponse }

/**
 * Utility class for UrlReader implementations to create valid ReadUrlResponse
 * instances from common response primitives.
 *
 * @public
 */
export declare class ReadUrlResponseFactory {
    /**
     * Resolves a ReadUrlResponse from a Readable stream.
     */
    static fromReadable(stream: Readable, options?: ReadUrlResponseFactoryFromStreamOptions): Promise<ReadUrlResponse>;
    /**
     * Resolves a ReadUrlResponse from an old-style NodeJS.ReadableStream.
     */
    static fromNodeJSReadable(oldStyleStream: NodeJS.ReadableStream, options?: ReadUrlResponseFactoryFromStreamOptions): Promise<ReadUrlResponse>;
}

/**
 * An options object for {@link ReadUrlResponseFactory} factory methods.
 *
 * @public
 */
export declare type ReadUrlResponseFactoryFromStreamOptions = {
    etag?: string;
};

/**
 * A winston formatting function that finds occurrences of filteredKeys
 * and replaces them with the corresponding identifier.
 *
 * @public
 */
export declare function redactWinstonLogLine(info: winston.Logform.TransformableInfo): winston.Logform.TransformableInfo;

/**
 * Logs incoming requests.
 *
 * @public
 * @param logger - An optional logger to use. If not specified, the root logger will be used.
 * @returns An Express request handler
 */
export declare function requestLoggingHandler(logger?: LoggerService): RequestHandler;

/**
 * A factory for request loggers.
 *
 * @public
 */
export declare type RequestLoggingHandlerFactory = (logger?: LoggerService) => RequestHandler;

/**
 * Resolve a path relative to the root of a package directory.
 * Additional path arguments are resolved relative to the package dir.
 *
 * This is particularly useful when you want to access assets shipped with
 * your backend plugin package. When doing so, do not forget to include the assets
 * in your published package by adding them to `files` in your `package.json`.
 *
 * @public
 */
export declare function resolvePackagePath(name: string, ...paths: string[]): string;

/**
 * Resolves a target path from a base path while guaranteeing that the result is
 * a path that point to or within the base path. This is useful for resolving
 * paths from user input, as it otherwise opens up for vulnerabilities.
 *
 * @public
 * @param base - The base directory to resolve the path from.
 * @param path - The target path, relative or absolute
 * @returns A path that is guaranteed to point to or within the base path.
 */
export declare function resolveSafeChildPath(base: string, path: string): string;

/**
 * Options passed to the {@link ContainerRunner.runContainer} method.
 *
 * @public
 */
export declare type RunContainerOptions = {
    imageName: string;
    command?: string | string[];
    args: string[];
    logStream?: Writable;
    mountDirs?: Record<string, string>;
    workingDir?: string;
    envVars?: Record<string, string>;
    pullImage?: boolean;
};

export { SearchOptions }

export { SearchResponse }

export { SearchResponseFile }

/**
 * Creates and validates tokens for use during backend-to-backend
 * authentication.
 *
 * @public
 */
export declare class ServerTokenManager implements TokenManager {
    private readonly options;
    private readonly verificationKeys;
    private signingKey;
    private privateKeyPromise;
    private currentTokenPromise;
    /**
     * Creates a token manager that issues static fake tokens and never fails
     * authentication. This can be useful for testing.
     */
    static noop(): TokenManager;
    static fromConfig(config: Config, options: ServerTokenManagerOptions): ServerTokenManager;
    private constructor();
    private generateKeys;
    getToken(): Promise<{
        token: string;
    }>;
    authenticate(token: string): Promise<void>;
}

/**
 * Options for {@link ServerTokenManager}.
 *
 * @public
 */
export declare interface ServerTokenManagerOptions {
    /**
     * The logger to use.
     */
    logger: LoggerService;
}

/**
 * A helper for building backend service instances.
 *
 * @public
 */
export declare type ServiceBuilder = {
    /**
     * Sets the service parameters based on configuration.
     *
     * @param config - The configuration to read
     */
    loadConfig(config: Config): ServiceBuilder;
    /**
     * Sets the port to listen on.
     *
     * If no port is specified, the service will first look for an environment
     * variable named PORT and use that if present, otherwise it picks a default
     * port (7007).
     *
     * @param port - The port to listen on
     */
    setPort(port: number): ServiceBuilder;
    /**
     * Sets the host to listen on.
     *
     * '' is express default, which listens to all interfaces.
     *
     * @param host - The host to listen on
     */
    setHost(host: string): ServiceBuilder;
    /**
     * Sets the logger to use for service-specific logging.
     *
     * If no logger is given, the default root logger is used.
     *
     * @param logger - A winston logger
     */
    setLogger(logger: LoggerService): ServiceBuilder;
    /**
     * Enables CORS handling using the given settings.
     *
     * If this method is not called, the resulting service will not have any
     * built in CORS handling.
     *
     * @param options - Standard CORS options
     */
    enableCors(options: cors.CorsOptions): ServiceBuilder;
    /**
     * Configure self-signed certificate generation options.
     *
     * If this method is not called, the resulting service will use sensible defaults
     *
     * @param options - Standard certificate options
     */
    setHttpsSettings(settings: {
        certificate: {
            key: string;
            cert: string;
        } | {
            hostname: string;
        };
    }): ServiceBuilder;
    /**
     * Adds a router (similar to the express .use call) to the service.
     *
     * @param root - The root URL to bind to (e.g. "/api/function1")
     * @param router - An express router
     */
    addRouter(root: string, router: Router | RequestHandler): ServiceBuilder;
    /**
     * Set the request logging handler
     *
     * If no handler is given the default one is used
     *
     * @param requestLoggingHandler - a factory function that given a logger returns an handler
     */
    setRequestLoggingHandler(requestLoggingHandler: RequestLoggingHandlerFactory): ServiceBuilder;
    /**
     * Sets an additional errorHandler to run before the defaultErrorHandler.
     *
     * For execution of only the custom error handler make sure to also invoke disableDefaultErrorHandler()
     * otherwise the defaultErrorHandler is executed at the end of the error middleware chain.
     *
     * @param errorHandler - an error handler
     */
    setErrorHandler(errorHandler: ErrorRequestHandler): ServiceBuilder;
    /**
     * Disables the default error handler
     */
    disableDefaultErrorHandler(): ServiceBuilder;
    /**
     * Starts the server using the given settings.
     */
    start(): Promise<Server>;
};

/**
 * Sets a completely custom default "root" logger.
 *
 * @remarks
 *
 * This is the logger instance that will be the foundation for all other logger
 * instances passed to plugins etc, in a given backend.
 *
 * Only use this if you absolutely need to make a completely custom logger.
 * Normally if you want to make light adaptations to the default logger
 * behavior, you would instead call {@link createRootLogger}.
 *
 * @public
 */
export declare function setRootLogger(newLogger: winston.Logger): void;

/**
 * SingleHostDiscovery is a basic PluginEndpointDiscovery implementation
 * that assumes that all plugins are hosted in a single deployment.
 *
 * The deployment may be scaled horizontally, as long as the external URL
 * is the same for all instances. However, internal URLs will always be
 * resolved to the same host, so there won't be any balancing of internal traffic.
 *
 * @public
 */
export declare class SingleHostDiscovery implements PluginEndpointDiscovery {
    private readonly internalBaseUrl;
    private readonly externalBaseUrl;
    /**
     * Creates a new SingleHostDiscovery discovery instance by reading
     * from the `backend` config section, specifically the `.baseUrl` for
     * discovering the external URL, and the `.listen` and `.https` config
     * for the internal one.
     *
     * The basePath defaults to `/api`, meaning the default full internal
     * path for the `catalog` plugin will be `http://localhost:7007/api/catalog`.
     */
    static fromConfig(config: Config, options?: {
        basePath?: string;
    }): SingleHostDiscovery;
    private constructor();
    getBaseUrl(pluginId: string): Promise<string>;
    getExternalBaseUrl(pluginId: string): Promise<string>;
}

/**
 * A custom status checking function, passed to {@link statusCheckHandler} and
 * {@link createStatusCheckRouter}.
 *
 * @public
 */
export declare type StatusCheck = () => Promise<any>;

/**
 * Express middleware for status checks.
 *
 * This is commonly used to implement healthcheck and readiness routes.
 *
 * @public
 * @param options - An optional configuration object.
 * @returns An Express error request handler
 */
export declare function statusCheckHandler(options?: StatusCheckHandlerOptions): Promise<RequestHandler>;

/**
 * Options passed to {@link statusCheckHandler}.
 *
 * @public
 */
export declare interface StatusCheckHandlerOptions {
    /**
     * Optional status function which returns a message.
     */
    statusCheck?: StatusCheck;
}

export { TokenManager }

/** @ignore */
declare type TransformedEnv<TEnv extends Record<string, unknown>, TEnvTransforms extends {
    [key in keyof TEnv]?: (dep: TEnv[key]) => unknown;
}> = {
    [key in keyof TEnv]: TEnvTransforms[key] extends (dep: TEnv[key]) => infer R ? R : TEnv[key];
};

export { UrlReader }

/**
 * A predicate that decides whether a specific {@link @backstage/backend-plugin-api#UrlReaderService} can handle a
 * given URL.
 *
 * @public
 */
export declare type UrlReaderPredicateTuple = {
    predicate: (url: URL) => boolean;
    reader: UrlReader;
};

/**
 * Helps construct {@link @backstage/backend-plugin-api#UrlReaderService}s.
 *
 * @public
 */
export declare class UrlReaders {
    /**
     * Creates a custom {@link @backstage/backend-plugin-api#UrlReaderService} wrapper for your own set of factories.
     */
    static create(options: UrlReadersOptions): UrlReader;
    /**
     * Creates a {@link @backstage/backend-plugin-api#UrlReaderService} wrapper that includes all the default factories
     * from this package.
     *
     * Any additional factories passed will be loaded before the default ones.
     */
    static default(options: UrlReadersOptions): UrlReader;
}

/**
 * Creation options for {@link @backstage/backend-plugin-api#UrlReaderService}.
 *
 * @public
 */
export declare type UrlReadersOptions = {
    /** Root config object */
    config: Config;
    /** Logger used by all the readers */
    logger: LoggerService;
    /** A list of factories used to construct individual readers that match on URLs */
    factories?: ReaderFactory[];
};

/**
 * useHotCleanup allows cleanup of ongoing effects when a module is
 * hot-reloaded during development. The cleanup function will be called
 * whenever the module itself or any of its parent modules is hot-reloaded.
 *
 * Useful for cleaning intervals, timers, requests etc
 *
 * @public
 * @example
 * ```ts
 * const intervalId = setInterval(doStuff, 1000);
 * useHotCleanup(module, () => clearInterval(intervalId));
 * ```
 * @param _module - Reference to the current module where you invoke the fn
 * @param cancelEffect - Fn that cleans up the ongoing effects
 */
export declare function useHotCleanup(_module: NodeModule, cancelEffect: () => void): void;

/**
 * Memoizes a generated value across hot-module reloads. This is useful for
 * stateful parts of the backend, e.g. to retain a database.
 *
 * @public
 * @example
 * ```ts
 * const db = useHotMemoize(module, () => createDB(dbParams));
 * ```
 *
 * **NOTE:** Do not use inside conditionals or loops,
 * same rules as for hooks apply (https://reactjs.org/docs/hooks-rules.html)
 *
 * @param _module - Reference to the current module where you invoke the fn
 * @param valueFactory - Fn that returns the value you want to memoize
 */
export declare function useHotMemoize<T>(_module: NodeModule, valueFactory: () => T): T;

export { }
